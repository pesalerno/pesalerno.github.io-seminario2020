---
layout: default
order: 5
title:  "Running STACKS"
date:   2019-08-05
time:   "11:30-13:00"
categories: main
instructor: "Becca"
materials: files/fakefile.txt
material-type: ""
lesson-type: Interactive
---


# Time to start the assembly process!

![](https://github.com/rdtarvin/IBS2019_Genomics-of-Biodiversity/blob/master/images/basic-assembly-steps.png?raw=true)<br>

In this workflow, we will use [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to check read quality, 
[fastx-toolkit](http://hannonlab.cshl.edu/fastx_toolkit/download.html) to trim reads, and 
[STACKS](http://catchenlab.life.illinois.edu/stacks/) for the assembly.<br><br>


Step 0. Use fastqc to check read quality.
---


	# fastqc is already installed, but if you wanted to download it, this is how: 
	# curl -L -O https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zip
	# unzip fastqc_v0.11.5.zip

	# let's take a look at fastqc options
	fastqc -h
	fastqc *.fastq


When the program is finished, take a look at what files are in the directory using `ls`.
fastqc produces a nice .html file that can be viewed in any browser. <br>
Since we are trying to get comfortable with the command line, let's open the file directly.

	open epiddrad_5M_R1__fastqc.html 


Sequencing quality scores, "Q", run from 20 to 40. In the fastq file, these are seen as ASCII characters. 
The values are log-scaled: 20 = 1/100 errors; 30 = 1/1000 errors. Anything below 20 is garbage and anything between 20 and 30 should be reviewed.
There appear to be errors in the kmer content, but really these are just showing where the barcodes and restriction enzyme sites are. 
Let's take a look at what ddRAD reads look like:

![](https://github.com/rdtarvin/IBS2019_Genomics-of-Biodiversity/blob/master/images/ddRAD-read.png?raw=true)

Ok, we can see that overall our data are of high quality (high Q scores, no weird tile patterns, no adaptor contamination). 
But let's also check out R2

	open epiddrad_5M_R2__fastqc.html 

Whoops what's going on here? When Illumina first came out with their HiSeq 4000 machines, the R2 had a lot of error.
Let's try installing a new program to clean up these reads.

```bash
curl -LO http://hannonlab.cshl.edu/fastx_toolkit/fastx_toolkit_0.0.13_binaries_MacOSX.10.5.8_i386.tar.bz2
tar -xjf fastx_toolkit_0.0.13_binaries_MacOSX.10.5.8_i386.tar.bz2
ls # the folder bin appeared!
rm fastx_toolkit_0.0.13_binaries_MacOSX.10.5.8_i386.tar.bz2 # remove the zipped file as we no longer need it 
./bin/fastx_trimmer -h
./bin/fastx_trimmer -t 50 -Q33 -i epiddrad_5M_R2_.fastq -o epiddrad_5M_R2_.fastq.trim # takes ~3min

# -t 50 to trim the last 50 bp from the end
# -Q33 so that it correctly interprets the quality scores
# -i = infile
# -o = outfile
```

While we are waiting let's do a quick exercise!<br>
[insert exercise]


OK, let's clean up our files and then move on to the assembly!!

```bash
mkdir fastqc
mv *__* fastqc 
mkdir old
mv epiddrad_5M_R2_.fastq old/epiddrad_5M_R2_.fastq.old
mv epiddrad_5M_R2_.fastq.trim epiddrad_5M_R2_.fastq
gzip *.fastq # takes a few min
```

While this is zipping, let's start on Step 1 in STACKS:<br>

Step 1. Demultiplex by barcode in **STACKS**
---

Demultiplexing your sequencing pools is always the first step in any pipeline. In stacks, the files you need for demultiplexing are: 

- barcodes+sample names (tab-delimited .txt file)

- process_radtags code (shell program from stacks)

First, let's take a look at the Stacks Manual for [process_radtags](http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php) to see how to set up our barcodes file. 

So, let's build the barcodes file for demultiplexing, where the first column will be the unique adapter sequence using the second column in 
this [text file](https://raw.githubusercontent.com/rdtarvin/IBS2019_Genomics-of-Biodiversity/master/data/epi_barcodes.txt), the second column is the index primer sequence (in this case, AGATCT), 
and the third column is the individual sample names (first column in the referenced file). 
<br>
Again, that was:<br>

unique adaptor (in R1) | index primer sequence (in R2) | sample name

**There are MANY ways to build this file.... how do you want to do it?**<br>
Save the file in the epi folder with the name `epi_barcodes_final.txt`

**NOTE**: whenever editing text files, first, NEVER use what you exported from excel or word directly… always check in a simple text editor (Text Wrangler, BBEdit, etc) and using “view invisible characters” to avoid unnecesary headaches of hidden characters or extra spaces/tabs, etc! Biggest waste of time in anything computing…


<details> 
  <summary>Side-note </summary>
   grep (Global regular expression print) is one of the most amazing things about text editors. <br>
   Try this on the epi_barcodes.txt file. Cmd+f, make sure 'grep' is checked, then search for
	<code>(.*)\t(.*)</code> and replace with <code>\2\tAGATCT\t\1</code>
</details> 

Ok! We have our barcode file, and we have our sequences. STACKS has already been installed on your machine,
so we just need to make a new folder called `demultiplex`, and then run the `process_radtags` program
to filter our reads for quality and then demultiplex them. Who remembers why we need to demultiplex?

	mkdir demultiplex

The general code we will use for process_radtags, running it from within the raw-data folder, is the following: 
	
	process_radtags -P -p . -b ./epi_barcodes_final.txt -o ./demultiplex -c -q -r -D --inline_index --renz_1 sphI --renz_2 mluCI -i gzfastq --disable_rad_check

This takes about 6 minutes to run, so let's talk about [??]<br>

***What do our demultiplexed files look like...?**



Step 2. Genotyping in **STACKS**
----

In most cases, having a reference genome is a good thing. However, STACKS is designed for non-model organisms, so in fact their [denovo_map](http://catchenlab.life.illinois.edu/stacks/comp/denovo_map.php) algorithms are superior and more self-contained than their [ref_map](http://catchenlab.life.illinois.edu/stacks/comp/ref_map.php) algorithms. 

In **ref_map.pl** you need to use [another alignment tool](https://github.com/lh3/bwa) prior to running stacks. So then, the pipeline workflow would have one extra step: 

	process_radtags
	GSNAP or bwa
	ref_map.pl

*"The ref_map.pl program takes as input aligned reads. It does not provide the assembly parameters that denovo_map.pl does and this is because the job of assembling the loci is being taken over by your aligner program (e.g. BWA or GSnap). You must take care that you have good alignmnets -- discarding reads with multiple alignments, making sure that you do not allow too many gaps in your sequences (otherwise loci with repeat elements can easily be collapsed during alignments), and take care not to allow soft-masking in the alignments. This occurs when an aligner can not make a full alignment and instead soft-masks the portion of the read that could not be aligned (pretending that this part of the read does not exist). **These factors, if not cared for, can cause spurious SNP calls and problems in the downstream analysis."***

A recent paper that came out, [Lost in Parameter Space: a roadmap for STACKS](http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12775/full), shows how building *ref_map* loci in STACKS is not very efficient, and loses too much data, which complicates the pipeline even more! Thus, the pipeline for *ref_map.pl*, using their so-called *"integrated"* method should be: 

	process_radtags #demultiplex
	denovo_map.pl #initial genotyping
	GSNAP or bwa #align raw reads to catalog loci from denovo
	integrate_alignments.py #integrate alignment information back into denovo ouput
	populations

So many steps!! 
	

Genotyping with denovo_map.pl
---

Before running the next step, we need to generate a population map file. Open a new text file and populate it with the following data:<br>
sample name | sample name
Save this file as `epi_popmap.txt`

<details> 
  <summary>Side-note </summary>
   Again! grep (Global regular expression print) is one of the most amazing things about text editors. <br>
   Copy the sample names from the epi_barcodes.txt file into a new file. Cmd+f, make sure 'grep' is checked, then search for
	<code>(\w*)\n</code> and replace with <code>\1\t\1\n</code>
</details> 

STACKS is often used for population genetics, but our dataset was designed for phylogenetics, so here we will consider each sample to be its own population
Let's start setting up denovo_map runs. et's make a list of the filenames that have sequences in them using the following command:

	cd demultiplex
	mkdir bad
	mkdir good
	mv *[a-b0-9]\.[1-2].fq.gz good # [0-9] is wildcard code for any one number between 0 and 9; [a-b] means any one letter between a and b; [1-2] means any one number between 1 and 2
	mv *q.gz bad
	mv *discards bad
	cd .. # move up one level

This list of filenames will be a part of the input for running *denovo_map.pl*, since you have to list all of the sequence files that will be used for input, rather than a directory containing them (and you don't want to include the discarded sequences!). 
Here is the general code we will use:

	mkdir denovo
	denovo_map.pl -T 2 -m 3 -M 2 -n 1 -o ./denovo --samples ./demultiplex/good --popmap epi_popmap.txt --paired # takes ~50min to run
	

The denovo code needs to have every single sequence that you will genotype listed in a single line. Thus, you need to build your **denovo_map** file with EVERY sequence that you will use separately.... **How should we do this?** 

OK, let's start **denovo_map**!!! Look at the terminal window as it runs.... what's happening currently...? While we wait, let's look more into the **STACKS** manual.<b>
This takes about 


[insert lecture]


#####
#####


One thing that is very important in stacks is troubleshooting parameter settings. The defaults in STACKS are **NOT GOOD** to use, and depending on the specifics of the dataset (divergence, number of populations, samples, etc) these parameters will vary a lot from one study to the other. The main parameters to mess with are: 

	m — specify a minimum number of identical, raw reads required to create a stack.
	M — specify the number of mismatches allowed between reads when processing a single individual (default 2).
	n — specify the number of mismatches allowed between reads (among inds.) when building the catalog (default 1).

**Note 1**: The higher the coverage, the higher the m parameter can be. 

**Note 2**: M should not be 1 (diploid data) but also should not be very high since it will begin to stack paralogs. 

**Note 3**: n will depend on how divergent our individuals/populations are. It should not be zero, since that would essentially allow zero SNPs, but 1 also seems unrealistically low (only a single difference between individuals in any given locus), so in these kinds of datasets we should have permutations that start from 2.  If you use n 1 it is likely to oversplit loci among populations that are more divergent. 

The same paper that discussed the issues with *ref_map.pl* that I mentioned previously, also mentions some tips for picking the ideal parameter settings for stacks... but, in general my recommendation would be: explore your dataset!!! Some general suggestions from it: 

- Setting the value of *m* in essence is choosing how much "error" you will include/exclude from your dataset. This parameter creates a trade-off between including error and excluding actual alleles/polymorphism. Higher values of *m* increase the average sample coverage, but decreases the number of assembled loci. After m=3 loci number is more stable.
- Setting the value *M* is a trade-off between overmerging (paralogs) and undermerging (splitting) loci.  It is **VERY dataset-specific** since it depends on polymorphism in the species/populations and in the amount of error (library prep and sequencing). 
- Setting the value *n* is also critical when it comes to overmerging and undermerging loci. There seems to be an unlimited number of loci that can be merged with the catalog wiht increasing n!! 
- Finally, authors suggest that a general rule for setting parameters is n=M, n=M-1, or n=M+1, and that M is the main parameter that needs to be explored for each dataset. 



However, given that these methods are still very new and that we still don't know how to "Easily" and properly assess error, the more permutations you do with the parameter settings, the more you will understand what your dataset is like, and the better/more "real" your loci/alleles will be. Here are some recommended permutations to run wiht your dataset:

Permutations | -m | -M | -n | --max_locus_stacks 
------------ | ------------- | ------------ | ------------- | ------------ |
a | 3 | 2 | 2 | 3 | 
b | 5 | 2 | 2 | 3 |
c | 7 | 2 | 2 | 3 | 
d | 3 | 3 | 2 | 3 |
e | 3 | 4 | 2 | 3 |
f | 3 | 5 | 2 | 3 |
g | 3 | 2 | 3 | 3 |
h | 3 | 2 | 4 | 3 |
i | 3 | 2 | 5 | 3 |
j | 3 | 2 | 2 | 4 |
k | 3 | 2 | 2 | 5 |

You can evaluate the number of loci, SNPs, and Fsts that you get from these parameters to assess "stability" of genotyping and pick optimal parameter settings. 

**NOW BACK TO OUR GENOTYPING IN STACKS....**

#####
#####


Getting the output with **populations**
----

The final step in the stacks pipeline is to run the program **populations**. Similar to step 7 in ipyrad, it outputs/summarizes your data into formats you specify. However, another super nice thing about this program is that it runs populations stats for you and puts them in a nice excel-readable output!! :D yay easy pogen stats!!  

To run **populations**, we first need to develop a popmap file, which simply contains names of sequences (first column)and some population code (second column)that they belong to, tab delimited. Our sample/file names alrady contain the population information, so try to build it yourself.... how do you want to do it???

 

Now, let's run **populations** using the following command:

	populations -P ./denovo -M ./epi_popmap.txt  --vcf  # takes ~3min
	# you can also produce outputs for STRUCTURE and GENEPOP, along with specific phylip files (but be careful in how you create these!) and full loci fasta files
	# this is the bare minimum for run populations, you can also filter for minimum number of individuals per population or minor allele frequency, etc. 
	# Pati will go more into filtering later
	

<br><br>

<a href="https://rdtarvin.github.io/IBS2019_Genomics-of-Biodiversity/"><button>Home</button></a>    <a href="https://rdtarvin.github.io/IBS2019_Genomics-of-Biodiversity/main/2019/08/05/07-raxml-epi.html"><button>Next Lesson</button></a>


## Appendix



There are actually several ways to look at .gz files, such as:
```
zless epiddrad_t200_R1_.fastq.gz # press 'q' to exit
gzcat epiddrad_t200_R1_.fastq.gz | head # the "|" pipes stdout to the program "head"
gzcat epiddrad_t200_R1_.fastq.gz | head -100 # shows the first 100 lines
```
