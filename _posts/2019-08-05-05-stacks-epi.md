---
layout: default
order: 5
title:  "demultiplexing and genotyping in stacks"
date:   2019-08-05
time:   "11:45-12:30"
categories: main
instructor: "Becca & Pati"
materials: files/fakefile.txt
material-type: ""
lesson-type: Interactive
---


# Time to start the assembly process!

![](https://github.com/rdtarvin/IBS2019_Genomics-of-Biodiversity/blob/master/images/basic-assembly-steps.png?raw=true)<br>

In this workflow, we will use [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to check read quality, 
[fastx-toolkit](http://hannonlab.cshl.edu/fastx_toolkit/download.html) to trim reads, and 
[STACKS](http://catchenlab.life.illinois.edu/stacks/) for the assembly.<br><br>



Step 1. Demultiplex by barcode in **STACKS**
---

Demultiplexing your sequencing pools is always the first step in any pipeline. In stacks, the files you need for demultiplexing are: 

- barcodes+sample names (tab-delimited .txt file)

- process_radtags code (shell program from stacks)

First, let's take a look at the Stacks Manual for [process_radtags](http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php) to see how to set up our barcodes file. 

Let's build the barcodes file for demultiplexing, where the first column will be the unique adapter sequence using the second column in 
this [text file](https://raw.githubusercontent.com/rdtarvin/IBS2019_Genomics-of-Biodiversity/master/data/epi_barcodes.txt) and the second column is the individual sample names (first column in the referenced file). 
<br><br>
Again, that was:<br>

unique adaptor (in R1) |  sample name

**There are MANY ways to build this file.... how do you want to do it?**<br>
Save the file in the epi folder with the name `epi_barcodes_final.txt`

**NOTE**: whenever editing text files, first, NEVER use what you exported from excel or word directly… always check in a simple text editor (Text Wrangler, BBEdit, etc) and using “view invisible characters” to avoid unnecesary headaches of hidden characters or extra spaces/tabs, etc! Biggest waste of time in anything computing…


<details> 
  <summary>Side-note </summary>
   grep (Global regular expression print) is one of the most amazing things about text editors. <br>
   Try this on the epi_barcodes.txt file once downloaded. Cmd+f, make sure 'grep' is checked, then search for
	<code>(.*)\t(.*)</code> and replace with <code>\2\t\1</code>
</details> 

Ok! We have our barcode file, and we have our sequences. STACKS has already been installed on your machine,
so we just need to make a new folder called `demultiplex`, and then run the `process_radtags` program
to filter our reads for quality and then demultiplex them. Who remembers why we need to demultiplex?

	mkdir demultiplex

The general code we will use for process_radtags, running it from within the epi folder, is the following: 
	
	process_radtags -P -p . -b ./epi_barcodes_final.txt -o ./demultiplex -c -q -r -D --inline_null --renz_1 sphI --renz_2 mluCI 
<br>
This takes about 6 minutes to run, so let's talk about the parameters used in [process_radtags](http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php)<br>
[or we can do a short exercise here pati]<br>

	# -P means reads are paired
	# -p means path to directory with our sequence files ('.' means 'here!')
	# -b indicates path to barcodes file
	# -o is for output directory
	# -c tells the program to remove reads with Ns
	# -q tells the program to remove low-quality reads
	# -r tells the program to "rescue" barcodes with RADtags
	# -D tells the program to save the discarded reads

	# you would alter these parameters depending how you make your libraries
	# --inline_null tells the program that the first barcode is inline and the second is absent (recall we removed the second inline barcode with fastx-toolkit)
	# --renz_1 is the first enzyme (cut site present in R1)
	# --renz_2 is the second enzyme (cut site present in R2)



***What do our demultiplexed files look like...?**



Step 2. Genotyping in **STACKS**
----

In most cases, having a reference genome is a good thing. However, STACKS is designed for non-model organisms, so in fact their [denovo_map](http://catchenlab.life.illinois.edu/stacks/comp/denovo_map.php) algorithms are superior and more self-contained than their [ref_map](http://catchenlab.life.illinois.edu/stacks/comp/ref_map.php) algorithms. 

In **ref_map.pl** you need to use [another alignment tool](https://github.com/lh3/bwa) prior to running stacks. So then, the pipeline workflow would have one extra step: 

	process_radtags
	GSNAP or bwa
	ref_map.pl

*"The ref_map.pl program takes as input aligned reads. It does not provide the assembly parameters that denovo_map.pl does and this is because the job of assembling the loci is being taken over by your aligner program (e.g. BWA or GSnap). You must take care that you have good alignmnets -- discarding reads with multiple alignments, making sure that you do not allow too many gaps in your sequences (otherwise loci with repeat elements can easily be collapsed during alignments), and take care not to allow soft-masking in the alignments. This occurs when an aligner can not make a full alignment and instead soft-masks the portion of the read that could not be aligned (pretending that this part of the read does not exist). **These factors, if not cared for, can cause spurious SNP calls and problems in the downstream analysis."***

A recent paper that came out, [Lost in Parameter Space: a roadmap for STACKS](http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12775/full), shows how building *ref_map* loci in STACKS is not very efficient, and loses too much data, which complicates the pipeline even more! Thus, the pipeline for *ref_map.pl*, using their so-called *"integrated"* method should be: 

	process_radtags #demultiplex
	denovo_map.pl #initial genotyping
	GSNAP or bwa #align raw reads to catalog loci from denovo
	integrate_alignments.py #integrate alignment information back into denovo ouput
	populations

So many steps!! 
	

Genotyping with denovo_map.pl
---

Before running the next step, we need to generate a population map file. Open a new text file and populate it with the following data:<br>
sample name | sample name
Save this file as `epi_popmap.txt`

<details> 
  <summary>Side-note </summary>
   Again! grep (Global regular expression print) is one of the most amazing things about text editors. <br>
   Copy the sample names from the epi_barcodes.txt file into a new file. Cmd+f, make sure 'grep' is checked, then search for
	<code>(\w*)\n</code> and replace with <code>\1\t\1\n</code>
</details> 

STACKS is often used for population genetics, but our dataset was designed for phylogenetics, so here we will consider each sample to be its own population
Let's start setting up denovo_map runs. et's make a list of the filenames that have sequences in them using the following command:

	cd demultiplex
	mkdir bad
	mkdir good
	mv *[a-b0-9]\.[1-2].fq.gz good # [0-9] is wildcard code for any one number between 0 and 9; [a-b] means any one letter between a and b; [1-2] means any one number between 1 and 2
	mv *q.gz bad
	mv *discards bad
	cd .. # move up one level

This list of filenames will be a part of the input for running *denovo_map.pl*, since you have to list all of the sequence files that will be used for input, rather than a directory containing them (and you don't want to include the discarded sequences!). 
Here is the general code we will use:

	mkdir denovo
	denovo_map.pl -T 2 -m 3 -M 2 -n 1 -o ./denovo --samples ./demultiplex/good --popmap epi_popmap.txt --paired # takes ~50min to run

OK, let's start **denovo_map**!!! Look at the terminal window as it runs.... what's happening currently...? While we wait, let's look more into the **STACKS** manual.<b>



[insert lecture]


#####
#####


One thing that is very important in stacks is troubleshooting parameter settings. The defaults in STACKS are **NOT GOOD** to use, and depending on the specifics of the dataset (divergence, number of populations, samples, etc) these parameters will vary a lot from one study to the other. The main parameters to mess with are: 

	m — specify a minimum number of identical, raw reads required to create a stack.
	M — specify the number of mismatches allowed between reads when processing a single individual (default 2).
	n — specify the number of mismatches allowed between reads (among inds.) when building the catalog (default 1).

**Note 1**: The higher the coverage, the higher the m parameter can be. 

**Note 2**: M should not be 1 (diploid data) but also should not be very high since it will begin to stack paralogs. 

**Note 3**: n will depend on how divergent our individuals/populations are. It should not be zero, since that would essentially allow zero SNPs, but 1 also seems unrealistically low (only a single difference between individuals in any given locus), so in these kinds of datasets we should have permutations that start from 2.  If you use n 1 it is likely to oversplit loci among populations that are more divergent. 

The same paper that discussed the issues with *ref_map.pl* that I mentioned previously, also mentions some tips for picking the ideal parameter settings for stacks... but, in general my recommendation would be: explore your dataset!!! Some general suggestions from it: 

- Setting the value of *m* in essence is choosing how much "error" you will include/exclude from your dataset. This parameter creates a trade-off between including error and excluding actual alleles/polymorphism. Higher values of *m* increase the average sample coverage, but decreases the number of assembled loci. After m=3 loci number is more stable.
- Setting the value *M* is a trade-off between overmerging (paralogs) and undermerging (splitting) loci.  It is **VERY dataset-specific** since it depends on polymorphism in the species/populations and in the amount of error (library prep and sequencing). 
- Setting the value *n* is also critical when it comes to overmerging and undermerging loci. There seems to be an unlimited number of loci that can be merged with the catalog wiht increasing n!! 
- Finally, authors suggest that a general rule for setting parameters is n=M, n=M-1, or n=M+1, and that M is the main parameter that needs to be explored for each dataset. 



However, given that these methods are still very new and that we still don't know how to "Easily" and properly assess error, the more permutations you do with the parameter settings, the more you will understand what your dataset is like, and the better/more "real" your loci/alleles will be. Here are some recommended permutations to run wiht your dataset:

Permutations | -m | -M | -n | --max_locus_stacks 
------------ | ------------- | ------------ | ------------- | ------------ |
a | 3 | 2 | 2 | 3 | 
b | 5 | 2 | 2 | 3 |
c | 7 | 2 | 2 | 3 | 
d | 3 | 3 | 2 | 3 |
e | 3 | 4 | 2 | 3 |
f | 3 | 5 | 2 | 3 |
g | 3 | 2 | 3 | 3 |
h | 3 | 2 | 4 | 3 |
i | 3 | 2 | 5 | 3 |
j | 3 | 2 | 2 | 4 |
k | 3 | 2 | 2 | 5 |

You can evaluate the number of loci, SNPs, and Fsts that you get from these parameters to assess "stability" of genotyping and pick optimal parameter settings. 

**NOW BACK TO OUR GENOTYPING IN STACKS....**

#####
#####

[would be nice to chat about what ustacks, cstacks, sstacks, and gstacks do]

<a href="https://rdtarvin.github.io/IBS2019_Genomics-of-Biodiversity/main/2019/08/05/04-RAD-libraries.html"><button>Previous Lesson</button></a><a href="https://rdtarvin.github.io/IBS2019_Genomics-of-Biodiversity/"><button>Home</button></a>    <a href="https://rdtarvin.github.io/IBS2019_Genomics-of-Biodiversity/main/2019/08/05/06-stacks-pipeline.html"><button>Next Lesson</button></a>


## Appendix

If you're unable to perform the process_radtags step, you can download the complete demultiplex folder [here](https://drive.google.com/drive/folders/1b-ro3RLB9pVR0qC7XpnUA0fEe6T3rkbF?usp=sharing).<br>
If you're unable to perform the denovo_map step, you can download the complete denovo folder (with populations output) [here](https://drive.google.com/drive/folders/1RdCsMo6YpOppUigrDgdDv7ju3xaBFD2G?usp=sharing).<br>